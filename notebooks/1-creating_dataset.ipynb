{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"e98a2530-43fe-4424-bc20-7bbf57fd5a05","_uuid":"db1f3958-d60a-47dc-92ef-5cca23bc8116","trusted":true},"source":["# Uploading the `Chest X-Ray` Dataset to Hugging Face"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"29a5eda8-0c6c-4633-b35a-c5cc8009bd07","_uuid":"c38f5a8c-feca-48ae-9255-60c8c4406836","trusted":true},"source":["This notebook's goal is to preprocess and upload the dataset [Chest X-Ray Images](https://data.mendeley.com/datasets/rscbjbr9sj) to the **Hugging Face Hub**. \n","\n","There will be two version of this dataset. The first is a raw version of the images as provided by the **Guangzhou Women and Children's Medical Center** of the **University of California San Diego**. The second will be a preprocessed version of the dataset. \n","\n","You can also find this dataset availble in [Kaggle](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"7af4596f-16dc-46fa-957f-1512df5610a7","_uuid":"38b0a1e5-4116-4399-906b-675002d8b82f","trusted":true},"source":["## Setup"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"fc7bcd44-4615-4f92-92bf-93d9338efdfe","_uuid":"0ed196eb-98fa-466f-8aec-a08692679f67","trusted":true},"source":["Let's first import the libraries we will use and create the constraints:"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"563302fe-ea5a-47f5-8a8b-81e9740d97c9","_uuid":"f8f83dbb-7426-4eda-b4f4-7906753c7982","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import os\n","import re\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","\n","# TensorFlow\n","import tensorflow as tf\n","from tensorflow import keras \n","from keras import utils\n","\n","# Hugging Face\n","import datasets\n","import huggingface_hub"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9213cf32-a48d-4e11-9ade-82daf13c97fc","_uuid":"32fd03d3-f476-4f47-9f60-ff8027d61801","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Local paths that store the files\n","RAW_DATA_PATH = \"../data/raw/pneumonia_xray/\"\n","DATA_PATH = \"../data/processed/\"\n","TFRECORDS_PATH = \"../data/processed/\"\n","\n","NAME_RAW_DATASET = \"mmenendezg/raw_pneumonia_x_ray\"\n","NAME_DATASET = \"mmenendezg/pneumonia_x_ray\"\n","AUTOTUNE = tf.data.AUTOTUNE\n","IMG_SIZE = (500, 500)\n","CLASSES = [\"Normal\", \"Pneumonia\"]"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"255a7bf1-57ac-4d75-95f9-a5628f6f7a20","_uuid":"ba696893-9242-4fb7-827d-413cc957a837","trusted":true},"source":["## Dataset Info"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"eed0d387-1dce-4581-b116-c539e004efe4","_uuid":"0b3919ea-cf49-4dca-8287-34dd001f6368","trusted":true},"source":["The dataset contains X-Ray chest images from independent patients. The images are classified into two classes:\n","\n",">- 0: Normal\n",">- 1: Pneumonia\n","\n","The shape, aspect ratio and size of the images vary. There are images with 3 channels of color (i.e., RGB color), and other images that have no channel (i.e., grayscale. The only channel is implicit). It is important to take this into consideration when preprocessing the dataset.\n","\n","The structure of the folders of the original dataset is the following:\n","\n","```\n","|-- pneumonia_x_ray\n","   |-- train\n","      |-- normal\n","      |-- pneumonia\n","   |-- test\n","      |-- normal\n","      |-- pneumonia\n","```"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"51caa7cf-5c17-4f12-b874-f898e0c927fc","_uuid":"44993e74-e20e-45db-94e6-29eb514492d0","trusted":true},"source":["## Create Raw dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"f836b13a-9530-4be5-b67e-b2d33ae11226","_uuid":"54e3e242-53ba-4526-920e-f00bd617f1f2","trusted":true},"source":["The first version of the dataset will be a raw version of the dataset. This will provide more flexibility to preprocess the images according to the project needs. \n","\n","It is important to login to Hugging Face to upload the dataset. In the code below change the `[TOKEN]` for the one provided by [Hugging Face](https://huggingface.co/settings/tokens)."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c804884d-b809-47a4-9a34-cc8ae5cac322","_uuid":"cf0f4b42-bf06-43a2-9d80-4e86f962668d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["!huggingface-cli login --token [TOKEN]"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"a8d6291e-172b-4db8-9ed7-9ae5dcaa3d26","_uuid":"c4bfb355-4e81-45cd-8cdf-eb2645e5e67d","trusted":true},"source":["The `load_dataset()` method allows us to download datasets stored in the Hugging Face Hub, or to load data stored locally. To load images from a local folder it is necessary to set `\"imagefolder\"` as the first argument, and the path of the folder containing the images in the `data_dir` argument. \n","\n","This will automatically identify the structure of the folders (see above) and create a `DatasetDict` containing the train and test splits, and it creates the two labels in each split."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1ae30ebf-b20a-45d8-8253-5be81231d11f","_uuid":"f90a275f-5f9b-42ec-95e7-fab95695e7e3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["raw_dataset = datasets.load_dataset(\"imagefolder\", data_dir=RAW_DATA_PATH)\n","raw_dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"35c0b9d5-888a-417f-a144-f550ac1fd82c","_uuid":"817a9940-cee1-41fe-a93a-5db574669782","trusted":true},"source":["Once we have loaded the data, we can push the dataset to the hub:"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"80d02856-b432-4b29-8345-118269a060ef","_uuid":"0a9fcccf-6a29-4e90-a75d-1760c2eb37bb","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["raw_dataset.push_to_hub(NAME_RAW_DATASET)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"4504a926-12e5-471d-ba1c-aa6bd9fc6f63","_uuid":"939e210d-ebed-4058-9a40-e539df4e676f","trusted":true},"source":["The dataset has been successfully uploaded to the [Hub](https://huggingface.co/datasets/mmenendezg/raw_pneumonia_x_ray). We can now download the data using the same name set when pushing the dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4bbbf06f-126a-4cb5-996c-dae9d8151fd0","_uuid":"b7426ba3-21d1-41e4-b65c-abacf2fafaf8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["pneumonia_x_ray = datasets.load_dataset(NAME_RAW_DATASET)\n","pneumonia_x_ray"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"37bae84d-2016-473d-8754-7f7065867649","_uuid":"d1a64c2f-fe3f-4111-8f74-6254cde0a3ba","trusted":true},"source":["## Create Preprocessed Dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"f56ab437-f889-4253-94f1-caba9e7a0a2f","_uuid":"ffb36047-70f8-4b49-bda7-892738c0feed","trusted":true},"source":["The raw images gives us a lot of flexibility to work with the data, but this creates some challenges when preprocessing the images to train a model. \n","\n","The second version of the dataset contains preprocessed images that solves the 2 main challenges of the raw data:\n","\n","> - It converts all images to RGB (i.e., All the images have 3 channels)\n","> - It resizes them to a fixed size, and therefore, a fixed aspect ratio (1:1)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"f89c7451-424c-4a8a-9e93-6d42f228d6ca","_uuid":"1c45161e-eaab-49cb-8bea-3516f0e2b32e","trusted":true},"source":["### Preprocess the images with TensorFlow"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"940c5846-483c-4dc5-971d-818a27693f44","_uuid":"74ec60bd-2bd1-4408-b3ad-ab04dc713d1d","trusted":true},"source":["It is necessary to preprocess the images. TensorFlow offers a wide variety of methods to load and preprocess images. The method `tf.keras.utils.image_dataset_from_directory()` provides all the preprocessing we need. Additionally, it infers the labels of the images based on the structure of the folders.\n","\n","When resizing the images, it is able to uses different interpolation methods. For this dataset we will use the `nearest` option that uses *k-nearest neighbors* algorithm to calculate the size of every pixel. This gives as result pixel values that are integers, and we do not need to process float values higher than 1. When working with images, it asumes that if the `dtype` of the tensors are float, the values should be betweeen 0 and 1."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"94065245-2fa5-4f13-90d1-d441b94d804b","_uuid":"4d105237-54d4-4b98-964f-4048e066a591","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def load_dataset(path: str, shuffle: bool = False) -> tf.data.Dataset:\n","    \"\"\"Loads a dataset of images from a directory.\n","\n","    Args:\n","        path: The path to the directory containing the images.\n","        shuffle: Whether to shuffle the dataset.\n","\n","    Returns:\n","        A `tf.data.Dataset` of images and labels.\n","    \"\"\"\n","    dataset = utils.image_dataset_from_directory(\n","        path,\n","        interpolation=\"nearest\",\n","        image_size=IMG_SIZE,\n","        label_mode=\"int\",\n","        color_mode=\"rgb\",\n","        batch_size=None,\n","        shuffle=shuffle,\n","        class_names=[\"normal\", \"pneumonia\"],\n","    )\n","    return dataset\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"72cbc629-3492-45f9-929b-3541a6b1dd3c","_uuid":"8eea400c-e21b-42ec-bd2e-7327da45527e","trusted":true},"source":["Let's load the images from the raw data folder:"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9d863417-c3d1-43df-a26d-e56d28e2cb3e","_uuid":"5d25ae85-e8e7-466f-a97e-419337d07d6c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["train_path = tf.io.gfile.join(RAW_DATA_PATH, \"train\")\n","test_path = tf.io.gfile.join(RAW_DATA_PATH, \"test\")\n","\n","train_ds = load_dataset(train_path, shuffle=True)\n","test_ds = load_dataset(test_path)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The original dataset only has `train` and `test` sets. Let's create a validation split set to upload it to the hub:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_validation_set(dataset: tf.data.Dataset, ratio: float = 0.3):\n","    # Calculate the number of images per label for the valid set\n","    normal_images = int(1349 * ratio)\n","    pneumo_images = int(3883 * ratio)\n","\n","    # Separate the dataset per labels\n","    normal_ds = dataset.filter(lambda image, label: label == 0)\n","    pneumo_ds = dataset.filter(lambda image, label: label == 1)\n","\n","    # Separate the datasets per splits\n","    normal_train = normal_ds.skip(normal_images)\n","    normal_valid = normal_ds.take(normal_images)\n","\n","    pneumo_train = pneumo_ds.skip(pneumo_images)\n","    pneumo_valid = pneumo_ds.take(pneumo_images)\n","\n","    # Concatenate the datasets\n","    train_ds = normal_train.concatenate(pneumo_train).shuffle(5000)\n","    valid_ds = normal_valid.concatenate(pneumo_valid)\n","\n","    return train_ds, valid_ds\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_ds, valid_ds = create_validation_set(train_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_train = 0\n","for _, _ in train_ds:\n","    n_train += 1\n","\n","n_valid = 0\n","for _, _ in valid_ds:\n","    n_valid += 1\n","\n","n_test = 0\n","for _, _ in test_ds:\n","    n_test += 1\n","\n","print(f\"Train: {n_train}\")\n","print(f\"Valid: {n_valid}\")\n","print(f\"Test: {n_test}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"13f11a7c-93ce-47c5-8543-f0449bc823f8","_uuid":"61599bcc-0b85-4f1a-8f21-0544d5737fcb","trusted":true},"source":["Once the images have been processed, we need to convert them to `datasets.Dataset` (Hugging Face dataset object). The `datasets` library does not provide an specific method to create a dataset from `tf.data.Dataset`. There are several ways to achieve this: using a generator, creating a dictionary, converting the dataset to a pandas dataframe, etc. In this case we will save the dataset to images in a local folder, and then we wil load the dataset using the `dataset.load_dataset()` method as above."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def save_image(image_array: np.array, filepath: str):\n","    \"\"\"Saves an image to a file.\n","\n","    Args:\n","        image_array: The image array to save.\n","        filepath: The path to the file to save the image to.\n","\n","    Returns:\n","        None.\n","    \"\"\"\n","    image = Image.fromarray(image_array)\n","    image.save(filepath)\n","\n","\n","def save_images(dataset: tf.data.Dataset, set_type: str = \"train\"):\n","    \"\"\"Saves images from a dataset to a directory.\n","\n","    Args:\n","        dataset: A `tf.data.Dataset` of images and labels.\n","        set_type: The type of dataset, either `\"train\"`, `\"validation\"` or `\"test\"`.\n","\n","    Returns:\n","        None.\n","    \"\"\"\n","    id_images = [0, 0]\n","    classes = [\"normal\", \"pneumonia\"]\n","    paths = [\n","        f\"../data/processed/{set_type}/{classes[0]}\",\n","        f\"../data/processed/{set_type}/{classes[1]}\",\n","    ]\n","    for path in paths:\n","        tf.io.gfile.makedirs(path)\n","\n","    for idx, (image, label) in enumerate(dataset):\n","        id_image = id_images[label.numpy()]\n","        image_path = tf.io.gfile.join(\n","            paths[label.numpy()], f\"{set_type}-{id_image}.jpeg\"\n","        )\n","        save_image(image.numpy(), image_path)\n","        id_images[label.numpy()] += 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"71b69984-f5fa-43cd-a38b-e4608c13d3c2","_uuid":"e98e3645-2720-405d-a96d-954962a48822","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["save_images(train_ds, \"train\")\n","save_images(valid_ds, \"validation\")\n","save_images(test_ds, \"test\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"bb05d2f2-f20b-42f0-8d69-be155626d369","_uuid":"d788189a-8246-4b90-898e-3a676320af82","trusted":true},"source":["### Upload preprocessed dataset to Hugging Face Hub"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"745aacd6-1a62-416b-95e6-c877733f1330","_uuid":"77eedf28-9730-4c16-9a68-34c067ac03d1","trusted":true},"source":["It is possible to load the whole dataset in a single line of code, but for a reason I was not able to find, this causes to duplicate the images. One alternative, is to load the sets separate and then to create a `datasets.DatasetDict` object containg both sets."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"01248515-8c90-45a7-a7da-21ac0d632af3","_uuid":"1f7d0284-5523-476d-9018-19255f664e43","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def create_and_upload_dataset_hf():\n","    \"\"\"Creates and uploads a dataset to the Hugging Face Hub.\n","\n","    This function creates a dataset from two directories, one for training and one for testing. \n","    The dataset is then uploaded to the Hugging Face Hub.\n","    \"\"\"\n","    train_path = tf.io.gfile.join(DATA_PATH, \"train\")\n","    valid_path = tf.io.gfile.join(DATA_PATH, \"validation\")\n","    test_path = tf.io.gfile.join(DATA_PATH, \"test\")\n","\n","    train_dataset = datasets.load_dataset(\"imagefolder\", data_dir=train_path, split=\"train\")\n","    valid_dataset = datasets.load_dataset(\"imagefolder\", data_dir=valid_path, split=\"validation\")\n","    test_dataset = datasets.load_dataset(\"imagefolder\", data_dir=test_path, split=\"test\")\n","    dataset = datasets.DatasetDict({\n","        \"train\": train_dataset,\n","        \"validation\": valid_dataset,\n","        \"test\": test_dataset\n","    })\n","    dataset.push_to_hub(NAME_DATASET)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9a049310-aeee-4ab1-852c-5e16256dd135","_uuid":"3cbf5d77-deec-44b9-9eb6-607f11a34f9c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["create_and_upload_dataset_hf()"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"6d66ffc7-d9fc-48f2-9f76-5e46dec7f32d","_uuid":"2d55737a-6192-49eb-bc8b-deb649eda499","trusted":true},"source":["The dataset has been successfully uploaded to the [Hub](https://huggingface.co/datasets/mmenendezg/pneumonia_x_ray)."]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"e7b2bf83-76a7-4834-b160-e5d1550a4491","_uuid":"43e1b039-2613-4e8e-bc8e-683d16face86","trusted":true},"source":["## Images per Classes"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"29162c76-5dfb-4d29-8cb0-efd00809502f","_uuid":"01ad8510-7e0f-443b-ab90-d211c3431aff","trusted":true},"source":["Finally, lets see if the classes are balanced or not."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9421ff01-6a3a-40b9-9b18-7c5cc03981bd","_uuid":"d61507d6-3de4-4257-b4f9-63c263a1f5e2","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def plot_examples_per_class():\n","    \"\"\"\n","    Plots the distribution of examples per class in the train and test datasets.\n","\n","    The function calculates the count of examples for each class in the train and test datasets,\n","    and then visualizes the distribution using a bar plot.\n","    \"\"\"\n","    count_train = [0, 0]\n","    count_valid = [0, 0]\n","    count_test = [0, 0]\n","\n","    for _, label in train_ds:\n","        count_train[label.numpy()] += 1\n","    \n","    for _, label in valid_ds:\n","        count_valid[label.numpy()] += 1\n","\n","    for _, label in test_ds:\n","        count_test[label.numpy()] += 1\n","    \n","    counts = {\n","        \"Classes\": [\"Normal\", \"Pneumonia\", \"Normal\", \"Pneumonia\", \"Normal\", \"Pneumonia\"],\n","        \"Examples\": count_train + count_valid + count_test,\n","        \"Set\": [\"Train\", \"Train\", \"Valid\", \"Valid\", \"Test\", \"Test\"],\n","    }\n","    data = pd.DataFrame.from_dict(counts)\n","    ax = sns.barplot(data, x=\"Examples\", y=\"Set\", hue=\"Classes\", palette=\"magma\")\n","    ax.bar_label(ax.containers[0])\n","    ax.bar_label(ax.containers[1])\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"39186571-e4c1-4642-b314-181f0876da3a","_uuid":"df099075-503c-4e1a-b398-ff6bb3822f96","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["plot_examples_per_class()"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"3c75c055-9eb7-443f-8d3d-21f2a18c817b","_uuid":"b81bdcdc-23c7-4e8a-9098-620e24017d48","trusted":true},"source":["The classes are unbalanced, specially the training set. Using the `accuracy` metric to evaluate a model trained on this dataset may not be the best option, and a better choice would be to use `recall`, `precision` or `F1-Score` metrics."]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"7e1c51b6-5bb8-4ba4-8d51-5b90972f5fcd","_uuid":"fca61254-e3b6-4637-bde0-012b5316988e","trusted":true},"source":["## References"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"a3e60079-a4eb-49b8-950d-f9b6e896e265","_uuid":"b0f8f660-f2ca-4b59-89bd-d34816a88a87","trusted":true},"source":[">**References**:\n",">\n","> - Kermany, Daniel; Zhang, Kang; Goldbaum, Michael (2018), “Large Dataset of Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images”, Mendeley Data, V3, doi: 10.17632/rscbjbr9sj.3"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
